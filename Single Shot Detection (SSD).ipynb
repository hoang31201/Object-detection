{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Object_detection_SSD.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"2SmPxLdegBT1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621515028875,"user_tz":-600,"elapsed":836,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"ea624742-d39c-4dee-af13-e12c7a1a5f0d"},"source":["%tensorflow_version 1.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l_WWkdeoDwOD","executionInfo":{"status":"ok","timestamp":1621515029392,"user_tz":-600,"elapsed":1349,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}}},"source":["import os\n","import re"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"er-bY2cvraLE","executionInfo":{"status":"ok","timestamp":1621515029393,"user_tz":-600,"elapsed":1346,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}}},"source":["# Parameter, model etc. Setup\n","# Repository link to clone/use\n","repo_url = 'https://github.com/hoang31201/Object-detection'\n","\n","# Number of training steps.\n","num_steps = 10000  # 200000 Increase the steps as required.\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","#Define the models to use (Already available in the )\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'ssd_inception_v2': { # <---- We will this model\n","        'model_name': 'ssd_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'ssd_inception_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 8\n","    }\n","}\n","\n","# Pick the model you want to use\n","selected_model = 'ssd_inception_v2'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colab's GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YyxMmRw6PJfA","executionInfo":{"status":"ok","timestamp":1621515030382,"user_tz":-600,"elapsed":2331,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"7d35ef12-58a5-4842-aeae-53a5f27c0b66"},"source":["%cd /content\n","\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","!git pull"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'Object-detection'...\n","remote: Enumerating objects: 702, done.\u001b[K\n","remote: Counting objects: 100% (702/702), done.\u001b[K\n","remote: Compressing objects: 100% (362/362), done.\u001b[K\n","remote: Total 702 (delta 339), reused 698 (delta 338), pack-reused 0\u001b[K\n","Receiving objects: 100% (702/702), 6.41 MiB | 20.08 MiB/s, done.\n","Resolving deltas: 100% (339/339), done.\n","/content/Object-detection\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gH_z_isPSSXt","executionInfo":{"status":"ok","timestamp":1621515040644,"user_tz":-600,"elapsed":12588,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"19f414e0-1661-489e-f565-576952af3a46"},"source":["%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools tf_slim\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content\n","fatal: destination path 'models' already exists and is not an empty directory.\n","/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0_e5Nd-EB4W","executionInfo":{"status":"ok","timestamp":1621515046784,"user_tz":-600,"elapsed":18723,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"96eee475-b56f-4373-ad6f-689b13ad00cd"},"source":["%cd {repo_dir_path}\n","\n","!python xml_to_csv.py -i data/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","!python xml_to_csv.py -i data/test -o data/annotations/test_labels.csv\n","\n","!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/train --label_map data/annotations/label_map.pbtxt\n","\n","!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/test --label_map data/annotations/label_map.pbtxt"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/Object-detection\n","Successfully converted xml to csv.\n","Generate `data/annotations/label_map.pbtxt`\n","Successfully converted xml to csv.\n","WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0520 12:50:43.217707 140423042979712 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0520 12:50:43.269159 140423042979712 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/Object-detection/data/annotations/train.record\n","WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0520 12:50:46.219417 139679670130560 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0520 12:50:46.242707 139679670130560 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/Object-detection/data/annotations/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NGWmkIyWJwyw","executionInfo":{"status":"ok","timestamp":1621515046784,"user_tz":-600,"elapsed":18718,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}}},"source":["# Define the Train, test records and the label map\n","test_record_fname = '/content/BloodRBC/data/annotations/test.record'\n","train_record_fname = '/content/BloodRBC/data/annotations/train.record'\n","label_map_pbtxt_fname = '/content/BloodRBC/data/annotations/label_map.pbtxt'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4KMba_Q-IUp1","executionInfo":{"status":"ok","timestamp":1621515052300,"user_tz":-600,"elapsed":24230,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"99d4c7e7-8355-4eba-f844-0ee0be9d386c"},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q96F2UvYIbm3","executionInfo":{"status":"ok","timestamp":1621515052302,"user_tz":-600,"elapsed":24227,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"52b8a1ab-84ff-4064-a192-92c118e37a26"},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content/models/research/pretrained_model\n","total 197M\n","drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n","drwxr-xr-x 25 root   root 4.0K May 20 12:50 ..\n","-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n","-rw-r--r--  1 345018 5000  98M Feb  1  2018 frozen_inference_graph.pb\n","-rw-r--r--  1 345018 5000  96M Feb  1  2018 model.ckpt.data-00000-of-00001\n","-rw-r--r--  1 345018 5000  18K Feb  1  2018 model.ckpt.index\n","-rw-r--r--  1 345018 5000 3.5M Feb  1  2018 model.ckpt.meta\n","-rw-r--r--  1 345018 5000 4.0K Feb  1  2018 pipeline.config\n","drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"mpCq7AO5IgtN","executionInfo":{"status":"ok","timestamp":1621515053209,"user_tz":-600,"elapsed":25129,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"c066757f-eb09-455b-f243-fde7f4cc2c2b"},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"ism0Cw0yIndU","executionInfo":{"status":"ok","timestamp":1621515053209,"user_tz":-600,"elapsed":25125,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}}},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"jhGIdczSIp3p","executionInfo":{"status":"ok","timestamp":1621515053211,"user_tz":-600,"elapsed":25125,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSGxHyDrItim","executionInfo":{"status":"ok","timestamp":1621515054075,"user_tz":-600,"elapsed":25986,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}}},"source":["num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6r1CoqK4KpMj","executionInfo":{"status":"ok","timestamp":1621515054077,"user_tz":-600,"elapsed":25985,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"fb2cbe92-6d2d-41a8-ed14-b25cfe6a4f60"},"source":["print(pipeline_fname)\n","!cat {pipeline_fname}"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/content/models/research/object_detection/samples/configs/ssd_inception_v2_coco.config\n","# SSD with Inception v2 configuration for MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  ssd {\n","    num_classes: 1\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","        reduce_boxes_in_lowest_layer: true\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 3\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_inception_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","      override_base_feature_extractor_hyperparams: true\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000\n","        iou_threshold: 0.99\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 0\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 12\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.004\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n","  from_detection_checkpoint: true\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 10000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/BloodRBC/data/annotations/train.record\"\n","  }\n","  label_map_path: \"/content/BloodRBC/data/annotations/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 8000\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/BloodRBC/data/annotations/test.record\"\n","  }\n","  label_map_path: \"/content/BloodRBC/data/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PvDnQGXJKqzb","executionInfo":{"status":"ok","timestamp":1621515054601,"user_tz":-600,"elapsed":26505,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}}},"source":["model_dir = 'training/'\n","# Optionally remove content in output model directory to fresh start.\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZmDIi3zK1-x","executionInfo":{"status":"ok","timestamp":1621515056021,"user_tz":-600,"elapsed":27922,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"9fc4c1a4-776d-43c7-ed14-dd95f19021ee"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":16,"outputs":[{"output_type":"stream","text":["--2021-05-20 12:50:54--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 52.200.34.95, 54.159.163.191, 54.159.34.239, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|52.200.34.95|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13832437 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.5’\n","\n","ngrok-stable-linux- 100%[===================>]  13.19M  15.8MB/s    in 0.8s    \n","\n","2021-05-20 12:50:55 (15.8 MB/s) - ‘ngrok-stable-linux-amd64.zip.5’ saved [13832437/13832437]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xQNesOBfLCoZ","executionInfo":{"status":"ok","timestamp":1621515056021,"user_tz":-600,"elapsed":27918,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}}},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdrMUYRgLDwj","executionInfo":{"status":"ok","timestamp":1621515056022,"user_tz":-600,"elapsed":27917,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}}},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7RGX9j-LGO2","executionInfo":{"status":"ok","timestamp":1621515056494,"user_tz":-600,"elapsed":28383,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"32cdb5a8-b8ce-42e2-fdf3-83ffb43d4926"},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":19,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","IndexError: list index out of range\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M62xyg0SFwLU","executionInfo":{"status":"ok","timestamp":1621515061916,"user_tz":-600,"elapsed":33801,"user":{"displayName":"Tri Hoang Nguyen","photoUrl":"","userId":"08708948486318645835"}},"outputId":"94f84367-ca26-4062-ef01-2e5241bbffea"},"source":["!pip install lvis"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (0.5.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n","Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.23)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VxJvoXF0LOem","outputId":"47933691-5a23-4aad-f727-57d619e3ea8f"},"source":["!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0520 12:51:04.982504 140385757763456 model_lib.py:812] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting train_steps: 10000\n","I0520 12:51:04.982742 140385757763456 config_util.py:552] Maybe overwriting train_steps: 10000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0520 12:51:04.982819 140385757763456 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0520 12:51:04.982881 140385757763456 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0520 12:51:04.982943 140385757763456 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0520 12:51:04.983029 140385757763456 model_lib.py:828] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","I0520 12:51:04.983099 140385757763456 model_lib.py:865] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fad9b575310>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0520 12:51:04.983566 140385757763456 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fad9b575310>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fad9b6e8b00>) includes params argument, but params are not passed to Estimator.\n","W0520 12:51:04.983817 140385757763456 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fad9b6e8b00>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0520 12:51:04.984230 140385757763456 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0520 12:51:04.984411 140385757763456 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0520 12:51:04.984626 140385757763456 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0520 12:51:04.990181 140385757763456 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/BloodRBC/data/annotations/train.record']\n","I0520 12:51:05.016470 140385757763456 dataset_builder.py:163] Reading unweighted datasets: ['/content/BloodRBC/data/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/BloodRBC/data/annotations/train.record']\n","I0520 12:51:05.018439 140385757763456 dataset_builder.py:80] Reading record datasets for input file: ['/content/BloodRBC/data/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0520 12:51:05.018666 140385757763456 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0520 12:51:05.018788 140385757763456 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0520 12:51:05.025866 140385757763456 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0520 12:51:05.047637 140385757763456 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad9b596090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","W0520 12:51:05.084164 140385757763456 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad9b596090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fad9b6e8f80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0520 12:51:05.303727 140385757763456 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fad9b6e8f80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:111: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0520 12:51:05.305865 140385757763456 deprecation.py:323] From /content/models/research/object_detection/inputs.py:111: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0520 12:51:05.314360 140385757763456 deprecation.py:323] From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:200: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0520 12:51:05.438965 140385757763456 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:200: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0520 12:51:06.288222 140385757763456 deprecation.py:323] From /content/models/research/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Calling model_fn.\n","I0520 12:51:06.794027 140385757763456 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0520 12:51:07.173459 140385757763456 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 12:51:11.056499 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 12:51:11.094886 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 12:51:11.130667 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 12:51:11.166492 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 12:51:11.202809 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 12:51:11.239203 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0520 12:51:16.404520 140385757763456 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","INFO:tensorflow:Done calling model_fn.\n","I0520 12:51:25.371786 140385757763456 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0520 12:51:25.373471 140385757763456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0520 12:51:29.631377 140385757763456 monitored_session.py:240] Graph was finalized.\n","2021-05-20 12:51:29.638163: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2021-05-20 12:51:29.638435: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5638fbce3480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-05-20 12:51:29.638473: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-05-20 12:51:29.641479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-05-20 12:51:29.653698: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2021-05-20 12:51:29.653758: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (e858ef6d809d): /proc/driver/nvidia/version does not exist\n","INFO:tensorflow:Running local_init_op.\n","I0520 12:51:35.765806 140385757763456 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0520 12:51:36.246817 140385757763456 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n","I0520 12:51:48.070572 140385757763456 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n","INFO:tensorflow:loss = 19.512436, step = 1\n","I0520 12:52:09.528056 140385757763456 basic_session_run_hooks.py:262] loss = 19.512436, step = 1\n","INFO:tensorflow:Saving checkpoints for 58 into training/model.ckpt.\n","I0520 13:01:58.978883 140385757763456 basic_session_run_hooks.py:606] Saving checkpoints for 58 into training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/BloodRBC/data/annotations/test.record']\n","I0520 13:02:01.562412 140385757763456 dataset_builder.py:163] Reading unweighted datasets: ['/content/BloodRBC/data/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/BloodRBC/data/annotations/test.record']\n","I0520 13:02:01.563914 140385757763456 dataset_builder.py:80] Reading record datasets for input file: ['/content/BloodRBC/data/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0520 13:02:01.564797 140385757763456 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad8e0f44d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","W0520 13:02:01.627936 140385757763456 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad8e0f44d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fad9315cef0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0520 13:02:01.872786 140385757763456 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fad9315cef0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0520 13:02:02.674172 140385757763456 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:02:06.983907 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:02:07.031984 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:02:07.077542 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:02:07.123415 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:02:07.168334 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:02:07.214293 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0520 13:02:08.184358 140385757763456 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0520 13:02:08.449590 140385757763456 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Done calling model_fn.\n","I0520 13:02:09.251937 140385757763456 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-05-20T13:02:09Z\n","I0520 13:02:09.273092 140385757763456 evaluation.py:255] Starting evaluation at 2021-05-20T13:02:09Z\n","INFO:tensorflow:Graph was finalized.\n","I0520 13:02:09.916885 140385757763456 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-58\n","I0520 13:02:09.919267 140385757763456 saver.py:1284] Restoring parameters from training/model.ckpt-58\n","INFO:tensorflow:Running local_init_op.\n","I0520 13:02:11.789417 140385757763456 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0520 13:02:12.108371 140385757763456 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 68 images.\n","I0520 13:02:35.397017 140383414920960 coco_evaluation.py:293] Performing evaluation on 68 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0520 13:02:35.398410 140383414920960 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0520 13:02:35.402980 140383414920960 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.18s).\n","Accumulating evaluation results...\n","DONE (t=0.06s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n","INFO:tensorflow:Finished evaluation at 2021-05-20-13:02:38\n","I0520 13:02:38.772878 140385757763456 evaluation.py:275] Finished evaluation at 2021-05-20-13:02:38\n","INFO:tensorflow:Saving dict for global step 58: DetectionBoxes_Precision/mAP = 3.725603e-05, DetectionBoxes_Precision/mAP (large) = 2.2840479e-05, DetectionBoxes_Precision/mAP (medium) = 0.000112412796, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.00027447686, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.008575381, DetectionBoxes_Recall/AR@100 (large) = 0.005147059, DetectionBoxes_Recall/AR@100 (medium) = 0.018994413, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 21.684053, Loss/localization_loss = 9.122154, Loss/regularization_loss = 0.48175254, Loss/total_loss = 31.287956, global_step = 58, learning_rate = 0.004, loss = 31.287956\n","I0520 13:02:38.773432 140385757763456 estimator.py:2049] Saving dict for global step 58: DetectionBoxes_Precision/mAP = 3.725603e-05, DetectionBoxes_Precision/mAP (large) = 2.2840479e-05, DetectionBoxes_Precision/mAP (medium) = 0.000112412796, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.00027447686, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.008575381, DetectionBoxes_Recall/AR@100 (large) = 0.005147059, DetectionBoxes_Recall/AR@100 (medium) = 0.018994413, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 21.684053, Loss/localization_loss = 9.122154, Loss/regularization_loss = 0.48175254, Loss/total_loss = 31.287956, global_step = 58, learning_rate = 0.004, loss = 31.287956\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 58: training/model.ckpt-58\n","I0520 13:02:40.097731 140385757763456 estimator.py:2109] Saving 'checkpoint_path' summary for global step 58: training/model.ckpt-58\n","INFO:tensorflow:global_step/sec: 0.0917116\n","I0520 13:10:19.902036 140385757763456 basic_session_run_hooks.py:692] global_step/sec: 0.0917116\n","INFO:tensorflow:loss = 6.5406427, step = 101 (1090.377 sec)\n","I0520 13:10:19.905369 140385757763456 basic_session_run_hooks.py:260] loss = 6.5406427, step = 101 (1090.377 sec)\n","INFO:tensorflow:Saving checkpoints for 111 into training/model.ckpt.\n","I0520 13:12:07.155867 140385757763456 basic_session_run_hooks.py:606] Saving checkpoints for 111 into training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/BloodRBC/data/annotations/test.record']\n","I0520 13:12:09.880759 140385757763456 dataset_builder.py:163] Reading unweighted datasets: ['/content/BloodRBC/data/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/BloodRBC/data/annotations/test.record']\n","I0520 13:12:09.881908 140385757763456 dataset_builder.py:80] Reading record datasets for input file: ['/content/BloodRBC/data/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0520 13:12:09.882104 140385757763456 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad8e0e5cd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","W0520 13:12:09.937707 140385757763456 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad8e0e5cd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fad87e97290> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0520 13:12:10.189414 140385757763456 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fad87e97290> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0520 13:12:10.912071 140385757763456 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:12:14.978190 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:12:15.031130 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:12:15.076284 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:12:15.122715 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:12:15.168173 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:12:15.223781 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0520 13:12:17.672594 140385757763456 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-05-20T13:12:17Z\n","I0520 13:12:17.694127 140385757763456 evaluation.py:255] Starting evaluation at 2021-05-20T13:12:17Z\n","INFO:tensorflow:Graph was finalized.\n","I0520 13:12:18.325033 140385757763456 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-111\n","I0520 13:12:18.327712 140385757763456 saver.py:1284] Restoring parameters from training/model.ckpt-111\n","INFO:tensorflow:Running local_init_op.\n","I0520 13:12:20.246446 140385757763456 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0520 13:12:20.565187 140385757763456 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 68 images.\n","I0520 13:12:43.908394 140383406528256 coco_evaluation.py:293] Performing evaluation on 68 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0520 13:12:43.909961 140383406528256 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0520 13:12:43.914672 140383406528256 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.13s).\n","Accumulating evaluation results...\n","DONE (t=0.07s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n","INFO:tensorflow:Finished evaluation at 2021-05-20-13:12:47\n","I0520 13:12:47.244874 140385757763456 evaluation.py:275] Finished evaluation at 2021-05-20-13:12:47\n","INFO:tensorflow:Saving dict for global step 111: DetectionBoxes_Precision/mAP = 0.00028617182, DetectionBoxes_Precision/mAP (large) = 0.00024885763, DetectionBoxes_Precision/mAP (medium) = 0.0016386292, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0014722993, DetectionBoxes_Precision/mAP@.75IOU = 2.863857e-05, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.03195021, DetectionBoxes_Recall/AR@100 (large) = 0.025, DetectionBoxes_Recall/AR@100 (medium) = 0.053072624, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 23.703714, Loss/localization_loss = 5.728385, Loss/regularization_loss = 0.4817585, Loss/total_loss = 29.91385, global_step = 111, learning_rate = 0.004, loss = 29.91385\n","I0520 13:12:47.245358 140385757763456 estimator.py:2049] Saving dict for global step 111: DetectionBoxes_Precision/mAP = 0.00028617182, DetectionBoxes_Precision/mAP (large) = 0.00024885763, DetectionBoxes_Precision/mAP (medium) = 0.0016386292, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0014722993, DetectionBoxes_Precision/mAP@.75IOU = 2.863857e-05, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.03195021, DetectionBoxes_Recall/AR@100 (large) = 0.025, DetectionBoxes_Recall/AR@100 (medium) = 0.053072624, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 23.703714, Loss/localization_loss = 5.728385, Loss/regularization_loss = 0.4817585, Loss/total_loss = 29.91385, global_step = 111, learning_rate = 0.004, loss = 29.91385\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 111: training/model.ckpt-111\n","I0520 13:12:47.251025 140385757763456 estimator.py:2109] Saving 'checkpoint_path' summary for global step 111: training/model.ckpt-111\n","INFO:tensorflow:Saving checkpoints for 164 into training/model.ckpt.\n","I0520 13:22:14.018655 140385757763456 basic_session_run_hooks.py:606] Saving checkpoints for 164 into training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/BloodRBC/data/annotations/test.record']\n","I0520 13:22:16.833023 140385757763456 dataset_builder.py:163] Reading unweighted datasets: ['/content/BloodRBC/data/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/BloodRBC/data/annotations/test.record']\n","I0520 13:22:16.834409 140385757763456 dataset_builder.py:80] Reading record datasets for input file: ['/content/BloodRBC/data/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0520 13:22:16.834680 140385757763456 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad883aa910>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","W0520 13:22:16.907100 140385757763456 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad883aa910>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fad883bb5f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0520 13:22:17.153410 140385757763456 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fad883bb5f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0520 13:22:17.895344 140385757763456 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:22:21.634495 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:22:21.678498 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:22:21.732846 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:22:21.777138 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:22:21.824265 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:22:21.869034 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0520 13:22:23.759552 140385757763456 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-05-20T13:22:23Z\n","I0520 13:22:23.786959 140385757763456 evaluation.py:255] Starting evaluation at 2021-05-20T13:22:23Z\n","INFO:tensorflow:Graph was finalized.\n","I0520 13:22:24.417270 140385757763456 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-164\n","I0520 13:22:24.419436 140385757763456 saver.py:1284] Restoring parameters from training/model.ckpt-164\n","INFO:tensorflow:Running local_init_op.\n","I0520 13:22:26.220339 140385757763456 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0520 13:22:26.511359 140385757763456 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 68 images.\n","I0520 13:22:49.828811 140383414920960 coco_evaluation.py:293] Performing evaluation on 68 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0520 13:22:49.829978 140383414920960 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0520 13:22:49.833994 140383414920960 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.15s).\n","Accumulating evaluation results...\n","DONE (t=0.06s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052\n","INFO:tensorflow:Finished evaluation at 2021-05-20-13:22:53\n","I0520 13:22:53.176266 140385757763456 evaluation.py:275] Finished evaluation at 2021-05-20-13:22:53\n","INFO:tensorflow:Saving dict for global step 164: DetectionBoxes_Precision/mAP = 0.00073224417, DetectionBoxes_Precision/mAP (large) = 0.0007597072, DetectionBoxes_Precision/mAP (medium) = 0.0024046362, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0035072584, DetectionBoxes_Precision/mAP@.75IOU = 3.9886792e-05, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.04591978, DetectionBoxes_Recall/AR@100 (large) = 0.052205883, DetectionBoxes_Recall/AR@100 (medium) = 0.026815642, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 24.543228, Loss/localization_loss = 10.04334, Loss/regularization_loss = 0.48173314, Loss/total_loss = 35.0683, global_step = 164, learning_rate = 0.004, loss = 35.0683\n","I0520 13:22:53.176759 140385757763456 estimator.py:2049] Saving dict for global step 164: DetectionBoxes_Precision/mAP = 0.00073224417, DetectionBoxes_Precision/mAP (large) = 0.0007597072, DetectionBoxes_Precision/mAP (medium) = 0.0024046362, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0035072584, DetectionBoxes_Precision/mAP@.75IOU = 3.9886792e-05, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.04591978, DetectionBoxes_Recall/AR@100 (large) = 0.052205883, DetectionBoxes_Recall/AR@100 (medium) = 0.026815642, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 24.543228, Loss/localization_loss = 10.04334, Loss/regularization_loss = 0.48173314, Loss/total_loss = 35.0683, global_step = 164, learning_rate = 0.004, loss = 35.0683\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 164: training/model.ckpt-164\n","I0520 13:22:53.181433 140385757763456 estimator.py:2109] Saving 'checkpoint_path' summary for global step 164: training/model.ckpt-164\n","INFO:tensorflow:global_step/sec: 0.0886131\n","I0520 13:29:08.403128 140385757763456 basic_session_run_hooks.py:692] global_step/sec: 0.0886131\n","INFO:tensorflow:loss = 5.696298, step = 201 (1128.500 sec)\n","I0520 13:29:08.404986 140385757763456 basic_session_run_hooks.py:260] loss = 5.696298, step = 201 (1128.500 sec)\n","INFO:tensorflow:Saving checkpoints for 221 into training/model.ckpt.\n","I0520 13:32:18.295182 140385757763456 basic_session_run_hooks.py:606] Saving checkpoints for 221 into training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/BloodRBC/data/annotations/test.record']\n","I0520 13:32:20.695354 140385757763456 dataset_builder.py:163] Reading unweighted datasets: ['/content/BloodRBC/data/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/BloodRBC/data/annotations/test.record']\n","I0520 13:32:20.696660 140385757763456 dataset_builder.py:80] Reading record datasets for input file: ['/content/BloodRBC/data/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0520 13:32:20.696815 140385757763456 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad88080790>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","W0520 13:32:20.754792 140385757763456 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad88080790>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fad85094950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0520 13:32:20.964416 140385757763456 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fad85094950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0520 13:32:21.605063 140385757763456 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:32:24.775753 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:32:24.811461 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:32:24.847196 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:32:24.884589 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:32:24.920799 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:32:24.958173 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0520 13:32:26.612082 140385757763456 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-05-20T13:32:26Z\n","I0520 13:32:26.631362 140385757763456 evaluation.py:255] Starting evaluation at 2021-05-20T13:32:26Z\n","INFO:tensorflow:Graph was finalized.\n","I0520 13:32:27.218777 140385757763456 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-221\n","I0520 13:32:27.220719 140385757763456 saver.py:1284] Restoring parameters from training/model.ckpt-221\n","INFO:tensorflow:Running local_init_op.\n","I0520 13:32:28.513978 140385757763456 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0520 13:32:28.719160 140385757763456 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 68 images.\n","I0520 13:32:48.427834 140383414920960 coco_evaluation.py:293] Performing evaluation on 68 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0520 13:32:48.429203 140383414920960 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.01s)\n","I0520 13:32:48.435419 140383414920960 coco_tools.py:138] DONE (t=0.01s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.07s).\n","Accumulating evaluation results...\n","DONE (t=0.06s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n","INFO:tensorflow:Finished evaluation at 2021-05-20-13:32:51\n","I0520 13:32:51.658481 140385757763456 evaluation.py:275] Finished evaluation at 2021-05-20-13:32:51\n","INFO:tensorflow:Saving dict for global step 221: DetectionBoxes_Precision/mAP = 0.00014146509, DetectionBoxes_Precision/mAP (large) = 8.999854e-05, DetectionBoxes_Precision/mAP (medium) = 0.00044257066, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0010911685, DetectionBoxes_Precision/mAP@.75IOU = 1.5321866e-06, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.017980637, DetectionBoxes_Recall/AR@100 (large) = 0.011580883, DetectionBoxes_Recall/AR@100 (medium) = 0.037430167, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 16.449173, Loss/localization_loss = 8.258015, Loss/regularization_loss = 0.48170516, Loss/total_loss = 25.188889, global_step = 221, learning_rate = 0.004, loss = 25.188889\n","I0520 13:32:51.658788 140385757763456 estimator.py:2049] Saving dict for global step 221: DetectionBoxes_Precision/mAP = 0.00014146509, DetectionBoxes_Precision/mAP (large) = 8.999854e-05, DetectionBoxes_Precision/mAP (medium) = 0.00044257066, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0010911685, DetectionBoxes_Precision/mAP@.75IOU = 1.5321866e-06, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.017980637, DetectionBoxes_Recall/AR@100 (large) = 0.011580883, DetectionBoxes_Recall/AR@100 (medium) = 0.037430167, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 16.449173, Loss/localization_loss = 8.258015, Loss/regularization_loss = 0.48170516, Loss/total_loss = 25.188889, global_step = 221, learning_rate = 0.004, loss = 25.188889\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 221: training/model.ckpt-221\n","I0520 13:32:51.662270 140385757763456 estimator.py:2109] Saving 'checkpoint_path' summary for global step 221: training/model.ckpt-221\n","INFO:tensorflow:Saving checkpoints for 276 into training/model.ckpt.\n","I0520 13:42:21.396453 140385757763456 basic_session_run_hooks.py:606] Saving checkpoints for 276 into training/model.ckpt.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0520 13:42:22.275863 140385757763456 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/BloodRBC/data/annotations/test.record']\n","I0520 13:42:24.388262 140385757763456 dataset_builder.py:163] Reading unweighted datasets: ['/content/BloodRBC/data/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/BloodRBC/data/annotations/test.record']\n","I0520 13:42:24.389677 140385757763456 dataset_builder.py:80] Reading record datasets for input file: ['/content/BloodRBC/data/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0520 13:42:24.389962 140385757763456 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad8495d950>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","W0520 13:42:24.453423 140385757763456 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fad8495d950>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fad84b9d680> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0520 13:42:24.706388 140385757763456 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fad84b9d680> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0520 13:42:25.453179 140385757763456 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:42:29.579169 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:42:29.628178 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:42:29.677505 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:42:29.724469 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:42:29.770793 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 13:42:29.815798 140385757763456 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0520 13:42:32.640648 140385757763456 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-05-20T13:42:32Z\n","I0520 13:42:32.664812 140385757763456 evaluation.py:255] Starting evaluation at 2021-05-20T13:42:32Z\n","INFO:tensorflow:Graph was finalized.\n","I0520 13:42:33.285495 140385757763456 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-276\n","I0520 13:42:33.287660 140385757763456 saver.py:1284] Restoring parameters from training/model.ckpt-276\n","INFO:tensorflow:Running local_init_op.\n","I0520 13:42:35.250282 140385757763456 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0520 13:42:35.581191 140385757763456 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 68 images.\n","I0520 13:42:59.240161 140383406528256 coco_evaluation.py:293] Performing evaluation on 68 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0520 13:42:59.242050 140383406528256 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.01s)\n","I0520 13:42:59.248729 140383406528256 coco_tools.py:138] DONE (t=0.01s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.04s).\n","Accumulating evaluation results...\n","DONE (t=0.07s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024\n","INFO:tensorflow:Finished evaluation at 2021-05-20-13:43:02\n","I0520 13:43:02.493823 140385757763456 evaluation.py:275] Finished evaluation at 2021-05-20-13:43:02\n","INFO:tensorflow:Saving dict for global step 276: DetectionBoxes_Precision/mAP = 0.00013411591, DetectionBoxes_Precision/mAP (large) = 0.00025061233, DetectionBoxes_Precision/mAP (medium) = 8.520683e-05, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0009186582, DetectionBoxes_Precision/mAP@.75IOU = 3.219834e-06, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.019502075, DetectionBoxes_Recall/AR@100 (large) = 0.02389706, DetectionBoxes_Recall/AR@100 (medium) = 0.0061452514, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 19.79683, Loss/localization_loss = 7.3813076, Loss/regularization_loss = 0.481689, Loss/total_loss = 27.659826, global_step = 276, learning_rate = 0.004, loss = 27.659826\n","I0520 13:43:02.494318 140385757763456 estimator.py:2049] Saving dict for global step 276: DetectionBoxes_Precision/mAP = 0.00013411591, DetectionBoxes_Precision/mAP (large) = 0.00025061233, DetectionBoxes_Precision/mAP (medium) = 8.520683e-05, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0009186582, DetectionBoxes_Precision/mAP@.75IOU = 3.219834e-06, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.019502075, DetectionBoxes_Recall/AR@100 (large) = 0.02389706, DetectionBoxes_Recall/AR@100 (medium) = 0.0061452514, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 19.79683, Loss/localization_loss = 7.3813076, Loss/regularization_loss = 0.481689, Loss/total_loss = 27.659826, global_step = 276, learning_rate = 0.004, loss = 27.659826\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 276: training/model.ckpt-276\n","I0520 13:43:02.499470 140385757763456 estimator.py:2109] Saving 'checkpoint_path' summary for global step 276: training/model.ckpt-276\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Af09Tvp3LWLt"},"source":["!ls {model_dir}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVYesNYYV48Q"},"source":["import re\n","import numpy as np\n","\n","output_directory = './fine_tuned_model'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWbdA6OlWCXc"},"source":["!ls {output_directory}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CpkFCIJTWKSG"},"source":["import os\n","\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DuBIZMUrWQDO"},"source":["!ls -alh {pb_fname}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1sm2AYFJWT7T"},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCjjxvw_YIl7"},"source":["%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util\n","\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)"],"execution_count":null,"outputs":[]}]}